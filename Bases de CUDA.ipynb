{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of thing to do:\n",
    "\n",
    "- Simple square example\n",
    "- Pointers\n",
    "- Basic C functions (Memcpy, Malloc)\n",
    "- Kernels\n",
    "- Launching a kernel\n",
    "- Maybe: ways to split our information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Elevando al cuadrado con CUDA\n",
    "\n",
    "Nuestra primer misión en CUDA es expicar ciertas sutilezas, para esto iniciaremos con un pequeño ejemplo.\n",
    "\n",
    "Supongamos que queremos elevar al cuadrado los números del 1 al 100. Un programa en python podríamos hacerlo de la siguiente manera.\n",
    "\n",
    "- Generamos un arreglo con los números del 1 al 100.\n",
    "- Utilizando un ciclo **for** elevamos cada uno de estos números y los metemos en un nuevo arreglo.\n",
    "\n",
    "Por último lo imprimos para mostrarlo al lector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121, 144, 169, 196, 225, 256, 289, 324, 361, 400, 441, 484, 529, 576, 625, 676, 729, 784, 841, 900, 961, 1024, 1089, 1156, 1225, 1296, 1369, 1444, 1521, 1600, 1681, 1764, 1849, 1936, 2025, 2116, 2209, 2304, 2401, 2500, 2601, 2704, 2809, 2916, 3025, 3136, 3249, 3364, 3481, 3600, 3721, 3844, 3969, 4096, 4225, 4356, 4489, 4624, 4761, 4900, 5041, 5184, 5329, 5476, 5625, 5776, 5929, 6084, 6241, 6400, 6561, 6724, 6889, 7056, 7225, 7396, 7569, 7744, 7921, 8100, 8281, 8464, 8649, 8836, 9025, 9216, 9409, 9604, 9801, 10000]\n"
     ]
    }
   ],
   "source": [
    "enteros = range(1,101)\n",
    "cuadrados = []\n",
    "\n",
    "for i in enteros:\n",
    "    cuadrados.append(i*i)\n",
    "\n",
    "print(cuadrados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, también hemos calculado el tiempo que se toma en hacer todo el proceso. Analicemos un poco nuestro algoritmo; el programa hace lo siguiente\n",
    "\n",
    "- Lee un número del arreglo.\n",
    "- Lo multiplica por sí mismo.\n",
    "- Guarda el resultado en un nuevo arreglo.\n",
    "- Si hay un siguiente número se regresa al punto inicial, si no termina.\n",
    "\n",
    "Supongamos a manera de esquema que cada multiplicación en nuestro procesador toma **2 ns** en realizarse, como estamos haciendo 100 multiplicaciones, entonces nos tomaría **200 ns** obtener todos y cada uno de los cuadrados que queremos.\n",
    "\n",
    "¿Cómo podríamos hacer esto en paralelo?\n",
    "\n",
    "Bueno, tal vez utilizando 100 trabajadores (a los cuales de aquí en adelante llamaremos threads o hilos) y haciendo que cada uno se encargue de leer un número del arreglo de entrada, multiplicarlo por sí mismo y escribirlo dentro de otro arreglo. Si vemos lo que hace un sólo thread no podríamos notar cuál es la diferencia entre el algoritmo en Python (algoritmo escrito en serie) y el algoritmo en parelelo. La principal diferencia radica en que en el algoritmo serial un solo thread se encarga de multiplicar todos los números, avanzando de uno en uno, mientras que en el algoritmo en paralelo le damos un número a cada uno de los 100 trabajadores y los hacemos multiplicarlos por sí mismos. Si cada uno de estos trabajadores tardara **10 ns** en hacer una multiplicación ¿Cuánto se tardarían en multiplicar los 100 números? Exacto, **10 ns**.\n",
    "\n",
    "Ahora veamos cómo quedaría éste código escrito en CUDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "#include <stdio.h>\n",
    "\n",
    "__global__ void cube(float * d_out, float * d_in){\n",
    "\tint idx = threadIdx.x;\n",
    "    float f = d_in[idx];\n",
    "    d_out[idx] = f*f*f;\n",
    "}\n",
    "\n",
    "int main(int argc, char ** argv) {\n",
    "\tconst int ARRAY_SIZE = 100;\n",
    "\tconst int ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
    "\n",
    "\t// generate the input array on the host\n",
    "\tfloat h_in[ARRAY_SIZE];\n",
    "\tfor (int i = 0; i < ARRAY_SIZE; i++) {\n",
    "\t\th_in[i] = float(i);\n",
    "\t}\n",
    "\tfloat h_out[ARRAY_SIZE];\n",
    "\n",
    "\t// declare GPU memory pointers\n",
    "\tfloat * d_in;\n",
    "\tfloat * d_out;\n",
    "\n",
    "\t// allocate GPU memory\n",
    "\tcudaMalloc((void**) &d_in, ARRAY_BYTES);\n",
    "\tcudaMalloc((void**) &d_out, ARRAY_BYTES);\n",
    "\n",
    "\t// transfer the array to the GPU\n",
    "\tcudaMemcpy(d_in, h_in, ARRAY_BYTES, cudaMemcpyHostToDevice);\n",
    "\n",
    "\t// launch the kernel\n",
    "\tcube<<<1, ARRAY_SIZE>>>(d_out, d_in);\n",
    "\n",
    "\t// copy back the result array to the CPU\n",
    "\tcudaMemcpy(h_out, d_out, ARRAY_BYTES, cudaMemcpyDeviceToHost);\n",
    "\n",
    "\t// print out the resulting array\n",
    "\tfor (int i =0; i < ARRAY_SIZE; i++) {\n",
    "\t\tprintf(\"%f\", h_out[i]);\n",
    "\t\tprintf(((i % 4) != 3) ? \"\\t\" : \"\\n\");\n",
    "\t}\n",
    "\n",
    "\tcudaFree(d_in);\n",
    "\tcudaFree(d_out);\n",
    "\n",
    "\treturn 0;\n",
    "}```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
