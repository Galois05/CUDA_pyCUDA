{
 "metadata": {
  "name": "",
  "signature": "sha256:af964718e2436aa39276608126f6a70c19ea7227a863bcd171f0313266b3c7d3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Introducci\u00f3n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "El c\u00f3mputo en *unidades de procesamiento gr\u00e1fico (GPU por sus siglas en ingl\u00e9s)* pertenece a una de las tendencias m\u00e1s nuevas en el mundo de la ciencia computacional. Su atractivo realmente reside en el hecho de que actualmente las tarjetas gr\u00e1ficas cuentan con un gran poder computacional. Por poner un ejemplo, al momento de escribir esto (*mediados de 2014*) la tarjeta [*Nvidia GeForce GTX TITAN Z*](http://www.nvidia.com/gtx-700-graphics-cards/gtx-titan-z/)  que se muestra en la figura 1 (*est\u00e1 guapa \u00bfNo?*) tiene **5760 n\u00facleos** y **12 GB** de memoria, con un rendimiento computacional pico de **8.1Tflops** en aritm\u00e9tica de precisi\u00f3n simple. Para poner \u00e9ste resultado en contexto [*Kan Balam*](http://es.wikipedia.org/wiki/Kan_Balam) la supercomputadora instalada en 2007 en la *UNAM* contaba con **7113GFlops**, i.e. un poco menos del poder computacional de la *Nvidia GeForce GTX TITAN Z*; la actual supercomputadora de la *UNAM*,  [*Miztli*](http://www.super.unam.mx/index.php/content-layouts?start=1) cuenta con **21.3Tflops** esto es aproximadamente **2.63** veces el poder computacional de la *GeForce GTX TITAN Z*.\n",
      "\n",
      "\n",
      "\n",
      "<img src=\"Titan-z.jpg\">\n",
      "\n",
      "<h6 align=\"center\">Figura 1: Nvidia GeForce GTX TITAN Z </h6>\n",
      "\n",
      "Pero es necesario hacer ciertas aclaraciones, en primer lugar, estas tarjetas son demasiado caras, y esto significa que uno no es capaz de comprarlas con lo que le paga su pap\u00e1 al lavar el coche. La tarjeta que se muestra en la figura 1 tiene como precio de lanzamiento **$2,999** y no son pesos, sino d\u00f3lares. De esta manera, el c\u00f3mputo intensivo en GPUs se sale del alcance del ama de casa promedio; as\u00ed \u00e9sta clase de c\u00f3mputo se restringe y por lo tanto no se encuentra a la mano de todo aqu\u00e9l que desee experimentar con ella.\n",
      "\n",
      "Al leer esto surgir\u00e1 una pregunta natural, y es \u00bfpor qu\u00e9 no se hace todo el c\u00f3mputo en GPUs? Hemos visto que su poder computacional actualmente es enorme, qu\u00e9 hace a los gobiernos y las universidades invertir millones para comprar una supercomputadora si pueden gastar tres mil d\u00f3lares y comprar una tarjeta gr\u00e1fica poderosa, \u00bfla pol\u00edtica les ha da\u00f1ado? La respuesta no tiene que ver con esto, sino con los procesadores gr\u00e1ficos en s\u00ed. Para entender esto se necesita saber c\u00f3mo funcionan los GPUs y para que eso no sea aburrido habremos de adentrarnos en la historia de estos espectaculares bichos."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Procesadores gr\u00e1ficos"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "El c\u00f3mputo en paralelo ha estado entre nosotros de una forma u otra por d\u00e9cadas. En sus primeros pasos, estaba confinado a usuarios con acceso a grandes y costosas computadoras. Hoy en d\u00eda, las cosas son diferentes. Casi cualquier usuario que tenga en su poder una computadora de escritorio o una laptop tiene *unidades centrales de procesamiento* (*CPU*) con varios n\u00facleos, e.g. el procesador [Intel i7](http://www.intel.com/products/processor/corei7/specifications.htm) que cuenta con **4 n\u00facleos f\u00edsicos y 4 n\u00facleos l\u00f3gicos**. Casi todos los procesadores en tel\u00e9fonos celulares y tablets cuentan con varios n\u00facleos. La raz\u00f3n principal para la ubicuidad de n\u00facleos m\u00faltiples en los CPUs se debe al fracaso de los dise\u00f1adores de procesadores para aumentar el rendimiento en dise\u00f1os de solamente un n\u00facleo, esto se lograba t\u00edpicamente incrementando la velocidad del reloj, \u00e9sta \u00faltima nos da una buena idea del rendimiento del procesador, e.g una *computadora personal* (*PC*) con un CPU [Intel 80486](http://en.wikipedia.org/wiki/Intel_80486) corriendo a **50 MHz** ser\u00e1 aproximadamente dos veces m\u00e1s r\u00e1pida que una que utilice el mismo CPU y cuente con la misma memoria pero corra a **25 MHz**\n",
      ", no siempre se cumple esta relaci\u00f3n, pero en buena aproximaci\u00f3n podemos decir que la velocidad del reloj nos da una buena idea de la velocidad de la computadora que lo usa; si los procesadores son de la misma familia, entonces la relaci\u00f3n anterior es v\u00e1lida. Como resultado de la incapacidad para aumentar la velocidad del reloj, los fabricantes tuvieron que ingeni\u00e1rselas; como resultado de esto, desde aproximadamente 2005 los dise\u00f1os de CPUs han \"escalado\" a una mayor cantidad de n\u00facleos, en lugar de \"escalar\" a mayores velocidades de reloj. Hoy en d\u00edaest\u00e1n disponibles CPUs que cuentan desde un par de n\u00facleos hasta decenas de \u00e9stos, sin embargo esta candidad de n\u00facleos en paralelo palidece ante la cantidad de n\u00facleos disponibles en la *GeForce GTX TITAN Z*. Los GPUs fueron dise\u00f1ados como *arquitecturas* altamente paralelas, a mitades de la d\u00e9cada de 1990 (una *arquitectura* en este sentido se entiende las partes que conforman al GPU o al CPU y c\u00f3mo se relacionan dichas partes entre s\u00ed). Fueron dise\u00f1ados para trabajar as\u00ed principalmente debido a que el procesamiento de gr\u00e1ficos es una actividad inherentemente paralela. La afirmaci\u00f3n anterior m\u00e1s o menos obvia si se piensa con cuidado, dado que en cierto sentido, cada pixel de la pantalla debe funcionar independientemente de sus vecinos; para ejemplificar esto necesitaremos la ayuda del plomero de la figura 2.\n",
      "\n",
      "<img src=\"8_Bit_Mario.png\">\n",
      "\n",
      "<h6 align=\"center\">Figura 2: Mario en 8 bits </h6>\n",
      "\n",
      "Como podemos ver, por ejemplo la mano derecha de Mario consta de 7 cuadros, 6 de ellos forman un rect\u00e1ngulo y el \u00faltimo debe ser su pulgar y est\u00e1 colocado al lado del rect\u00e1ngulo, ahora bien, a un lado del pulgar se ve el oberol de mario, este es rojo y no se encuentra de alguna manera relacionado con el color de la mano (a menos que est\u00e9 desnudo), por lo tanto necesita libertad para mostrar cualquier color, de hecho, siguiendo este razonamiento cada uno de los pixeles de la pantalla por separado debe estar mostrando el color que el dibujante le asign\u00f3 para poder obtener la imagen deseada. Las tarjetas gr\u00e1ficas son la justicia computacional en persona, se encargan de que las \u00f3rdenes dadas por el dibujante (el sistema) sean ejecutadas en la pantalla, es por esto que los GPUs fueron dise\u00f1ados para funcionar en paralelo, dado que el hecho de formar im\u00e1genes en una pantalla exige que cada pixel se encuentre trabajando de manera independiente de sus colegas.\n",
      "\n",
      "El uso de GPUs para *c\u00f3mputo de prop\u00f3sitos generales* (*GPGPU*), fue en sus inicios una serie de retos duros de matar. Se ten\u00eda que programar a la *interfaz de programaci\u00f3n de aplicaciones gr\u00e1ficas* (*API*), que demostr\u00f3 ser muy restrictiva en la clase de algoritmos que pod\u00edan ser mapeados al GPU. Incluso cuando dicho mapeo era posible, la programaci\u00f3n requerida para hacer esto realidad era dif\u00edcil y para nada intuitiva para los cient\u00edficos e ingenieros totalmente desligados a la vocaci\u00f3n de los gr\u00e1ficos de computadora. Ve\u00e1moslo desde el punto de vista de estas pobres almas atormentadas.Las tarjetas gr\u00e1ficas en ese entonces ten\u00edan \u00f3rdenes muy precisas, colorea este pixel de amarillo, aqu\u00e9l de rojo, aqu\u00e9l de azul, aqu\u00e9l de (*insert\u00e9 aqu\u00ed cualquiera de los dem\u00e1s colores que no me s\u00e9*), etc. Lo que quiere decir que si se deseaba programar en la tarjeta gr\u00e1fica se ten\u00eda que hacer un mapeo muy inteligente, por ejemplo declarar que un color fuera asignado a un n\u00famero y luego sumar colores. Uno cree que es f\u00e1cil, pero intuitivamente derivar un pixel morado y que d\u00e9 uno rojo simplemente es dif\u00edcil de entender, no s\u00f3lo eso, se hacen muchas operaciones con colores, y el resultado es otro color, tal vez esto ser\u00eda emocionante para *Salvador Dal\u00ed*, pero a decir verdad no era un espect\u00e1culo especialmente cautivante para los cient\u00edficos. Era demasiado trabajo y esfuerzo y somos muy flojos. Esto explica por qu\u00e9 el proceso de adoptar a los GPUs para c\u00f3mputo cient\u00edfico fue lento al principio.\n",
      "\n",
      "El horizonte se ilumin\u00f3 para el c\u00f3mputo en GPUs con la llegada de la arquitectura de **NVIDIA CUDA** en 2007. La arquitectura **CUDA** inclu\u00eda tanto componentes de *hardware* de los GPUs de NVIDIA y un ambiente de programaci\u00f3n de software que eliminaba las barreras que limitaron la adopci\u00f3n del GPGPU. Desde su primera aparici\u00f3n en 2007, CUDA tuvo una aceptaci\u00f3n tremenda, hasta el punto en que, en noviembre de 2010, tres de las supercomputadoras en el top cinco enlistadas en el top 500 usaban GPUs. En las lista de noviembre de 2012 la supercomputadora m\u00e1s r\u00e1pida contaba con el poder de los GPUs. Una de las razones para su r\u00e1pida adopci\u00f3n es que el modelo de programaci\u00f3n era simple. **CUDA C** la primera interfaz a la arquitectura CUDA, es b\u00e1sicamente **C** con unas pocas extensiones que permiten cargar porciones de un algoritmo para ser corridas en el GPU. Es entonces un acercamiento h\u00edbrido en donde tanto GPU como CPU son usados.\n",
      "\n",
      "Actualmente CUDA es usado en distintas \u00e1reas de la ciencia, en medicina se utiliza para detectar c\u00e1ncer de mama, originalmente este era detectado por mamograf\u00eda o rayos X, sin embargo frecuentemente estas pr\u00e1cticas llevaban a falsos positivos "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}