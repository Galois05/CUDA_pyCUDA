{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of things to do:\n",
    "\n",
    "- Gather\n",
    "- Scatter\n",
    "- Stencil\n",
    "- Transpose\n",
    "\n",
    "A thread Block programming example to show that it's not predefined the way the threads are launched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# El modelo de programación en paralelo\n",
    "\n",
    "El lector podrá ahora darse cuenta por sí mismo que hay diferencias al programar en paralelo, con respecto a la forma usual. La principal de ellas es que el GPU no es un procesador serial, sino un procesador *stream*. Un procesador serial, también conocido como arquitectura de von Neumann, ejecuta instrucciones serialmente, actualizando la memoria a medida que avanza. Un procesador en *stream* funciona de una manera ligeramente diferente, ejecutando una función (tal como un fragmento de programa) en un conjunto de registros de entrada, produciendo un conjunto de registros de salida (e.g. pixeles sombreados) en paralelo. Los procesadores en stream, típicamente se refieren a dicha función como *kernel* y al conjunto de registros como *stream* (muy imaginativos). La información es lanzada al procesador, operada vía una función *kernel*, y sacada a la memoria, como se muestra en la figura 1. Cada elemento pasado al procesador es procesado independientemente, sin ser influido por los demás elementos. Esto permite a la arquitectura ejecutar un programa en paralelo sin la necesidad de exponer las unidades paralelas o cualquier construcción en paralelo al programador. Es por dicha razón que al escribir la función kernel en el capítulo pasado no notamos el paralelismo, no fue sino hasta el momento de lanzar el kernel que vimos esto.\n",
    "\n",
    "![](http://http.developer.nvidia.com/GPUGems/elementLinks/fig37-01.jpg)\n",
    "\n",
    "<h6 align=\"center\">Figura 1: Modelo de ejecución de un programa en el GPU (imagen tomada de los GPUGems de NVIDIA) </h6>\n",
    "\n",
    "Y qué tal si quisiésemos hacer física con esto, sería increíblemente incómodo que el único tipo de dato que pudiésemos manejar fuera el sombreado de un pixel; sin embargo, gracias a los avances en GPU se pueden manejar registros que no necesariamente son pixeles y sombreados; bien podría ser un conjunto arbitrario de datos, por ejemplo puntos de una red y ecuaciones fisicas. Digamos, que queremos implementar una simulación simple de partículas libres y dejar que el GPU lleve a cabo la mayor parte de las operaciones físicas. Usando texturas de punto flotante y buffers de pixel (pbuffers), guardamos la posición de las partículas, valocidades, y orientaciones. Un kernel hace los cálculos necesarios para obtener la nueva posición de cada partícula. Para calcular todas y cada una de las nuevas posiciones simplemente tomamos un cuadrante que tenga tantos pixeles como partículas, tal y como se muestra en la figura 2. Las coordenadas de textura para el cuadrante indican al kernel cuál de las partículas guardadas procesará. El resultado guardado en el pbuffer contiene los valores de las nuevas posiciones.\n",
    "\n",
    "![](http://http.developer.nvidia.com/GPUGems/elementLinks/fig37-02.jpg)\n",
    "\n",
    "<h6 align=\"center\">Figura 2: Ejemplo de un sistema de partículas (imagen tomada de los GPUGems de NVIDIA) </h6>\n",
    "\n",
    "Este ejemplo de un sistema de partículas demuestra una obvia pero útil aplicación del GPU para el cómputo de propósito general (GPGPU). La operación de actualizar la posición de las partículas puede generalizarse al proceso de aplicar una función a un arreglo. Esta operación - también llamada mapeo en lenguajes de programación funcional - puede ser usada para una amplia variedad de aplicaciones.\n",
    "\n",
    "Pero **¿qué es este mapeo del que tanto hablamos?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patrones de comunicación\n",
    "\n",
    "## Mapeo\n",
    "\n",
    "En el mapeo, una función opera en cada elemento de un arreglo de entrada y produce un resultado, por ejemplo sumar a cada entrada de un vector un número, o multiplicar todo el vector por una constante, con la conveniencia de que lo que se lee en la posición *i* de la entrada sirve para obtener el resultado que se escribe en la posición *i* de la salida. Para procesar todos los elementos de la entrada en paralelo, una función de mapeo debe ser pura. Esto quiere decir que genera exactamente el mismo resultado para la misma entrada, y que su ejecución no tiene efectos secundarios.\n",
    "\n",
    "Dado que no hay necesidad de sincronizar a los threads, y no se comparte información, el patrón de mapeo se ajusta perfectamente a arquitecturas paralelas, de muchos núcleos. En las implementaciones en paralelo de los patrones de mapeo, cada thread ejecuta una instancia de una función mapeo y genera su correspondiente resultado. Éste patron es usado en muchos dominios, incluyendo el procesamiento de imágenes, simulaciones financieras, simulaciones físicas, etc.\n",
    "\n",
    "A continuación mostramos un código para multiplicar un vector de 100 entradas (predefinidas del 1 al 100) por un escalar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```C\n",
    "#include <stdio.h>\n",
    "\n",
    "#define ESCALAR 3\n",
    "\n",
    "__global__ void multiplicar_por_escalar(float * escalar, float * d_salida, float * d_entrada){\n",
    "\tint idx = threadIdx.x;\n",
    "    float f = d_entrada[idx];\n",
    "    d_salida[idx] = f*escalar;\n",
    "}\n",
    "\n",
    "int main(int argc, char ** argv) {\n",
    "\n",
    "\tconst int TAMANIO_ARREGLO = 100;\n",
    "\tconst int BYTES_ARREGLO = TAMANIO_ARREGLO * sizeof(float);\n",
    "\n",
    "\t// Generamos el arreglo de entrada en el anfitrion\n",
    "\tfloat h_entrada[TAMANIO_ARREGLO];\n",
    "    \n",
    "\tfor (int i = 0; i < TAMANIO_ARREGLO; i++) {\n",
    "\t\th_entrada[i] = float(i);\n",
    "\t}\n",
    "    \n",
    "\tfloat h_salida[TAMANIO_ARREGLO];\n",
    "\n",
    "\t// Declaramos apuntadores de memoria en GPU\n",
    "\tfloat * d_entrada;\n",
    "\tfloat * d_salida;\n",
    "\n",
    "\t// Reservamos memoria del GPU\n",
    "\tcudaMalloc((void**) &d_entrada, BYTES_ARREGLO);\n",
    "\tcudaMalloc((void**) &d_salida, BYTES_ARREGLO);\n",
    "\n",
    "\t// Copiamos informacion al GPU\n",
    "\tcudaMemcpy(d_entrada, h_entrada, BYTES_ARREGLO, cudaMemcpyHostToDevice);\n",
    "\n",
    "\t// Lanza el kernel\n",
    "\tmultiplicar_por_escalar<<<1, TAMANIO_ARREGLO>>>(ESCALAR, d_salida, d_entrada);\n",
    "\n",
    "\t// Copiamos el arreglo resultante al GPU\n",
    "\tcudaMemcpy(h_salida, d_salida, BYTES_ARREGLO, cudaMemcpyDeviceToHost);\n",
    "\n",
    "\t// Imprimimos el arreglo resultante\n",
    "\tfor (int i =0; i < TAMANIO_ARREGLO; i++) {\n",
    "\t\tprintf(\"%f \\n\", h_salida[i]);\n",
    "\t}\n",
    "\n",
    "\tcudaFree(d_entrada);\n",
    "\tcudaFree(d_salida);\n",
    "\n",
    "\treturn 0;\n",
    "}```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si al lector se le hace conocido el código anterior es porque en realidad es el visto en el capítulo anterior, salvo algunas modificaciones pequeñas. **¿Las pueden encontrar?**\n",
    "\n",
    "En este punto la pregunta en el aire debe ser **¿Qué demonios es `#define ESCALAR 3`?** Bueno, simplemente definimos una constante que se llama *ESCALAR* y que tiene como valor *3*.\n",
    "\n",
    "Visto esto, se deja como ejercicio al lector hacer un código (en la celda de abajo) que sume 3 a cada una de las entradas de un vector (pueden usar el vector que quieran, en especial el que hemos venido utilizando)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dispersar y reunir\n",
    "\n",
    "Los patrones dispersar (scatter) y reunir (gather) son similares a los patrones mapeo pero sus accesos a la memoria son aleatorios. Dispersar es una función mapeo que escribe en posiciones aleatorias, y reunir es la combinación de una función mapeo con accesos a memoria que leen de entradas aleatorias. Las implementacionesen paralelo de los patrones dispersar y reunir son similares a las implementaciones del mapeo. Dicho patrón se encuentra comunmente en aplicaciones estadísticas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```C\n",
    "#include <stdio.h>\n",
    "\n",
    "#define NUM_BLOCKS 16\n",
    "#define ANCHURA_BLOCK 1\n",
    "\n",
    "__global__ void hola()\n",
    "{\n",
    "    printf(\"Hola mundo! Soy un thread en el bloque %d\\n\", blockIdx.x);\n",
    "}\n",
    "\n",
    "\n",
    "int main(int argc,char **argv)\n",
    "{\n",
    "    // lanzar el kernel\n",
    "    hola<<<NUM_BLOCKS, ACHURA_BLOCK>>>();\n",
    "\n",
    "    // forzar a los printf() para que se muestren\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "    printf(\"Eso es todo amigos!\\n\");\n",
    "\n",
    "    return 0;\n",
    "}```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referencias\n",
    "\n",
    "1. [Curso de Udacity - Intro to Parallel Programming](https://www.udacity.com/course/intro-to-parallel-programming--cs344)\n",
    "2. [GPUGems - Capítulo 37](http://http.developer.nvidia.com/GPUGems/gpugems_ch37.html)\n",
    "3. [Paraprox: Pattern-Based Approximation for Data Parallel Applications](http://cccp.eecs.umich.edu/papers/samadi-asplos14.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Materiales adicionales\n",
    "\n",
    "1. [GPUGems](http://developer.nvidia.com/object/gpu_gems_home.html)\n",
    "2. [gpgpu.org](http://gpgpu.org/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
