{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "A thread Block programming example to show that it's not predefined the way the threads are launched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# El modelo de programación en paralelo\n",
    "\n",
    "El lector podrá ahora darse cuenta por sí mismo que hay diferencias al programar en paralelo, con respecto a la forma usual. La principal de ellas es que el GPU no es un procesador serial, sino un procesador *stream*. Un procesador serial, también conocido como arquitectura de von Neumann, ejecuta instrucciones serialmente, actualizando la memoria a medida que avanza. Un procesador en *stream* funciona de una manera ligeramente diferente, ejecutando una función (tal como un fragmento de programa) en un conjunto de registros de entrada, produciendo un conjunto de registros de salida (e.g. pixeles sombreados) en paralelo. Los procesadores en stream, típicamente se refieren a dicha función como *kernel* y al conjunto de registros como *stream* (muy imaginativos). La información es lanzada al procesador, operada vía una función *kernel*, y sacada a la memoria, como se muestra en la figura 1. Cada elemento pasado al procesador es procesado independientemente, sin ser influido por los demás elementos. Esto permite a la arquitectura ejecutar un programa en paralelo sin la necesidad de exponer las unidades paralelas o cualquier construcción en paralelo al programador. Es por dicha razón que al escribir la función kernel en el capítulo pasado no notamos el paralelismo, no fue sino hasta el momento de lanzar el kernel que vimos esto.\n",
    "\n",
    "![](http://http.developer.nvidia.com/GPUGems/elementLinks/fig37-01.jpg)\n",
    "\n",
    "<h6 align=\"center\">Figura 1: Modelo de ejecución de un programa en el GPU (imagen tomada de los GPUGems de NVIDIA) </h6>\n",
    "\n",
    "Y qué tal si quisiésemos hacer física con esto, sería increíblemente incómodo que el único tipo de dato que pudiésemos manejar fuera el sombreado de un pixel; sin embargo, gracias a los avances en GPU se pueden manejar registros que no necesariamente son pixeles y sombreados; bien podría ser un conjunto arbitrario de datos, por ejemplo puntos de una red y ecuaciones fisicas. Digamos, que queremos implementar una simulación simple de partículas libres y dejar que el GPU lleve a cabo la mayor parte de las operaciones físicas. Usando texturas de punto flotante y buffers de pixel (pbuffers), guardamos la posición de las partículas, valocidades, y orientaciones. Un kernel hace los cálculos necesarios para obtener la nueva posición de cada partícula. Para calcular todas y cada una de las nuevas posiciones simplemente tomamos un cuadrante que tenga tantos pixeles como partículas, tal y como se muestra en la figura 2. Las coordenadas de textura para el cuadrante indican al kernel cuál de las partículas guardadas procesará. El resultado guardado en el pbuffer contiene los valores de las nuevas posiciones.\n",
    "\n",
    "![](http://http.developer.nvidia.com/GPUGems/elementLinks/fig37-02.jpg)\n",
    "\n",
    "<h6 align=\"center\">Figura 2: Ejemplo de un sistema de partículas (imagen tomada de los GPUGems de NVIDIA) </h6>\n",
    "\n",
    "Este ejemplo de un sistema de partículas demuestra una obvia pero útil aplicación del GPU para el cómputo de propósito general (GPGPU). La operación de actualizar la posición de las partículas puede generalizarse al proceso de aplicar una función a un arreglo. Esta operación - también llamada mapeo en lenguajes de programación funcional - puede ser usada para una amplia variedad de aplicaciones.\n",
    "\n",
    "Pero **¿qué es este mapeo del que tanto hablamos?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patrones de comunicación\n",
    "\n",
    "## Mapeo\n",
    "\n",
    "En el mapeo, una función opera en cada elemento de un arreglo de entrada y produce un resultado, por ejemplo sumar a cada entrada de un vector un número, o multiplicar todo el vector por una constante, con la conveniencia de que lo que se lee en la posición *i* de la entrada sirve para obtener el resultado que se escribe en la posición *i* de la salida. Para procesar todos los elementos de la entrada en paralelo, una función de mapeo debe ser pura. Esto quiere decir que genera exactamente el mismo resultado para la misma entrada, y que su ejecución no tiene efectos secundarios.\n",
    "\n",
    "Dado que no hay necesidad de sincronizar a los threads, y no se comparte información, el patrón de mapeo se ajusta perfectamente a arquitecturas paralelas, de muchos núcleos. En las implementaciones en paralelo de los patrones de mapeo, cada thread ejecuta una instancia de una función mapeo y genera su correspondiente resultado. Éste patron es usado en muchos dominios, incluyendo el procesamiento de imágenes, simulaciones financieras, simulaciones físicas, etc.\n",
    "\n",
    "A continuación mostramos un código para multiplicar un vector de 100 entradas (predefinidas del 1 al 100) por un escalar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```C\n",
    "#include <stdio.h>\n",
    "\n",
    "#define ESCALAR 3\n",
    "\n",
    "__global__ void multiplicar_por_escalar(float * escalar, float * d_salida, float * d_entrada){\n",
    "\tint idx = threadIdx.x;\n",
    "    float f = d_entrada[idx];\n",
    "    d_salida[idx] = f*escalar;\n",
    "}\n",
    "\n",
    "int main(int argc, char ** argv) {\n",
    "\n",
    "\tconst int TAMANIO_ARREGLO = 100;\n",
    "\tconst int BYTES_ARREGLO = TAMANIO_ARREGLO * sizeof(float);\n",
    "\n",
    "\t// Generamos el arreglo de entrada en el anfitrion\n",
    "\tfloat h_entrada[TAMANIO_ARREGLO];\n",
    "    \n",
    "\tfor (int i = 0; i < TAMANIO_ARREGLO; i++) {\n",
    "\t\th_entrada[i] = float(i);\n",
    "\t}\n",
    "    \n",
    "\tfloat h_salida[TAMANIO_ARREGLO];\n",
    "\n",
    "\t// Declaramos apuntadores de memoria en GPU\n",
    "\tfloat * d_entrada;\n",
    "\tfloat * d_salida;\n",
    "\n",
    "\t// Reservamos memoria del GPU\n",
    "\tcudaMalloc((void**) &d_entrada, BYTES_ARREGLO);\n",
    "\tcudaMalloc((void**) &d_salida, BYTES_ARREGLO);\n",
    "\n",
    "\t// Copiamos informacion al GPU\n",
    "\tcudaMemcpy(d_entrada, h_entrada, BYTES_ARREGLO, cudaMemcpyHostToDevice);\n",
    "\n",
    "\t// Lanza el kernel\n",
    "\tmultiplicar_por_escalar<<<1, TAMANIO_ARREGLO>>>(ESCALAR, d_salida, d_entrada);\n",
    "\n",
    "\t// Copiamos el arreglo resultante al GPU\n",
    "\tcudaMemcpy(h_salida, d_salida, BYTES_ARREGLO, cudaMemcpyDeviceToHost);\n",
    "\n",
    "\t// Imprimimos el arreglo resultante\n",
    "\tfor (int i =0; i < TAMANIO_ARREGLO; i++) {\n",
    "\t\tprintf(\"%f \\n\", h_salida[i]);\n",
    "\t}\n",
    "\n",
    "\tcudaFree(d_entrada);\n",
    "\tcudaFree(d_salida);\n",
    "\n",
    "\treturn 0;\n",
    "}```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si al lector se le hace conocido el código anterior es porque en realidad es el visto en el capítulo anterior, salvo algunas modificaciones pequeñas. **¿Las pueden encontrar?**\n",
    "\n",
    "En este punto la pregunta en el aire debe ser **¿Qué es `#define ESCALAR 3`?** Bueno, simplemente definimos una constante que se llama *ESCALAR* y que tiene como valor *3*.\n",
    "\n",
    "Visto esto, **se deja como ejercicio al lector hacer un código (en la celda de abajo) que sume 3 a cada una de las entradas de un vector (pueden usar el vector que quieran, en especial el que hemos venido utilizando)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dispersar y reunir\n",
    "\n",
    "Los patrones dispersar (scatter) y reunir (gather) son similares a los patrones mapeo pero sus accesos a la memoria son aleatorios. Dispersar es una función mapeo que escribe en posiciones aleatorias, y reunir es la combinación de una función mapeo con accesos a memoria que leen de entradas aleatorias. Las implementacionesen paralelo de los patrones dispersar y reunir son similares a las implementaciones del mapeo. Dicho patrón se encuentra comunmente en aplicaciones estadísticas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducción\n",
    "\n",
    "Cuando una función combina todos los elementos de un arreglo de entrada para generar una salida única, se dice que está realizando una reducción. Si la función usada por el patrón de reducción es asociativa y conmutativa, por ejemplo, el [XOR](https://en.wikipedia.org/wiki/Exclusive_or), el orden en el cuál la operación de reducción es aplicada a las entradas no tiene importancia. En este caso, las implementaciones basadas en árboles pueden ser utilizadas para paralelizar dicha reducción. Las reducciones se pueden encontrar en diferentes áreas, como el aprendizaje de máquinas, física, y estadística; entre otras.\n",
    "\n",
    "Un ejemplo trivial de esto sería el promediar todas las entradas de un arreglo.\n",
    "\n",
    "**Ejercicio: Escribir un kernel que calcule dicho promedio**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Discuta consigo mismo, o con un amigo, ¿por qué podría no resultar buena idea realizar el promedio en el GPU?*\n",
    "\n",
    "Podemos obtener ayuda de nuestros amigos en los [foros de NVIDIA](https://devtalk.nvidia.com/default/topic/416372/performing-average-calculation-of-an-array-2048-2048-expedient-use-of-cuda-in-this-case-/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escaneo\n",
    "\n",
    "El escaneo aplica una función asociativa a un arreglo de entrada y genera un arreglo nuevo. Cada n-ésimo elemento del arreglo de salida es el resultado de aplicar la función escaneo a los primeros N (escaneo inclusivo) o N - 1 (escaneo exclusivo) elementos de entrada. El patrón de escaneo es usualmente utilizado en el contexto de procesamiento de señales, y aprendizaje de máquinas.\n",
    "\n",
    "*Discuta un ejemplo en donde se utilice el escaneo*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stencil\n",
    "\n",
    "En un patrón \"stencil\", cada elemento de salida es calculado aplicando la función a su correspondiente elemento en el arreglo de entrada, y a sus vecinos. Éste patrón es útil por ejemplo para hacer borrosa una imagen; si decidimos que en nuestra nueva imagen cada pixel tendrá el color del pixel que estaba originalmente en ese lugar promediado con el color de sus vecinos. Este patrón es usualmente encontrado en procesamiento de imágenes y física.\n",
    "\n",
    "*¿Habrá algún juego divertido en el que el patrón stencil sea útil?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partición\n",
    "\n",
    "El patrón de partición (o \"tile\") es similar al patrón stencil. El arreglo de entrada es separado en particiones y cada partición es procesada de manera separada. Cada partición es completamente independiente de las otras. Particionar es utilizando comunmente en aplicaciones que tienen paralelismo de datos para utilizar eficientemente las arquitecturas intrínsecas de jerarquía de memoria y así mejorar el rendimiento. Éste patrón es utilizado comunmente en dominios como procesamiento de imágenes, procesamiento de señales, y modelación en física. Más adelante en las notas se mostrará un ejemplo para exhibir la importancia de este patrón de comunicación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```C\n",
    "#include <stdio.h>\n",
    "\n",
    "#define NUM_BLOCKS 16\n",
    "#define ANCHURA_BLOCK 1\n",
    "\n",
    "__global__ void hola()\n",
    "{\n",
    "    printf(\"Hola mundo! Soy un thread en el bloque %d\\n\", blockIdx.x);\n",
    "}\n",
    "\n",
    "\n",
    "int main(int argc,char **argv)\n",
    "{\n",
    "    // lanzar el kernel\n",
    "    hola<<<NUM_BLOCKS, ACHURA_BLOCK>>>();\n",
    "\n",
    "    // forzar a los printf() para que se muestren\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "    printf(\"Eso es todo amigos!\\n\");\n",
    "\n",
    "    return 0;\n",
    "}```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referencias\n",
    "\n",
    "1. [Curso de Udacity - Intro to Parallel Programming](https://www.udacity.com/course/intro-to-parallel-programming--cs344)\n",
    "2. [GPUGems - Capítulo 37](http://http.developer.nvidia.com/GPUGems/gpugems_ch37.html)\n",
    "3. [Paraprox: Pattern-Based Approximation for Data Parallel Applications](http://cccp.eecs.umich.edu/papers/samadi-asplos14.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Materiales adicionales\n",
    "\n",
    "1. [GPUGems](http://developer.nvidia.com/object/gpu_gems_home.html)\n",
    "2. [gpgpu.org](http://gpgpu.org/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
