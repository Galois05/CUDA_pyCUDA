{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook empezaremos con un micro-curso de probabilidad usando nuestra nueva herramienta. En este momento es importante recalcar que a medida que vayamos avanzando en los notebooks, las contribuciones en código de los autores serán cada vez menores, puesto que consideramos que lo aprendido en la primera parte del curso, más la sencillez de PyCUDA proveen al lector las herramientas necesarias para poder hacer sus propios códigos desde 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Águila o sol (cara o cruz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al lanzar una moneda, uno puede decir con absoluta certeza que sólo una de las dos caras de la moneda verá hacia el frente, e incluso ir más allá: la probabilidad de caiga en cualquiera de las dos caras es de $\\frac{1}{2}$.\n",
    "\n",
    "Recomendamos leer sobre la visión \"frecuentista\" y \"bayesiana\" de las probabilidades que se le puede adjudicar a un evento. (Revisar las referencias)\n",
    "\n",
    "\n",
    "**Definición**: Llamamos Distribución de Probabilidad a la colección de todas las probabilidades de todos los eventos de una variable aleatorio $X$ asociada a un evento.\n",
    "\n",
    "Ejemplo: Al lanzar una moneda obtenemos dos posibles eventos. \n",
    "+ $X=$ Águila\n",
    "+ $X=$ Sol\n",
    "\n",
    "De este manera obtenemos que la Distribución de Probabilidad asociada al lanzar la moneda es: $$\\{ P(X = Águila) = \\frac{1}{2}, \\ P(X=Sol)= \\frac{1}{2} \\}$$\n",
    "\n",
    "En este ejemplo, las probabilidades son iguales en cada valor de $X$, por lo que llamamos a esta distribución *uniforme*. Pero, ¿qué tan uniforme es?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  El dado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambiaremos ahora a otro ejemplo un poco más complicado: el lanzamiento de un dado de 6 caras. No es difícil llegar a que, si el dado no está trucado, cada una de las caras tiene una probabilidad de $\\frac{1}{6}$ de quedar mirando hacia arriba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pasemos ahora a la programación.\n",
    "\n",
    "Como primer objetivo haremos que $N$ `threads` generen un número entero aleatorio entre $1$ y $6$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.  6.  3.  4.  5.  6.  5.  4.  5.  3.  2.  2.  6.  1.  2.  4.  5.  4.\n",
      "  6.  5.  2.  3.  2.  3.  2.  4.  6.  3.  1.  3.  5.  4.  5.  3.  4.  3.\n",
      "  1.  6.  6.  1.  2.  6.  5.  6.  4.  4.  1.  5.  2.  6.]\n"
     ]
    }
   ],
   "source": [
    "import pycuda.autoinit\n",
    "import pycuda.driver as cuda\n",
    "import numpy as np\n",
    "from pycuda.curandom import rand as curand\n",
    "from pycuda.compiler import SourceModule\n",
    "import pycuda.gpuarray as gpuarray\n",
    "\n",
    "# Escribimos el kernel que utilizaremos\n",
    "\n",
    "# El kernel toma un arreglo con N números aleatorios entre 0 y 1 y los convierte en números aleatorios\n",
    "# entre 1 y 6. \n",
    "\n",
    "mod = SourceModule(\"\"\"\n",
    "#include<stdio.h>\n",
    "#include<math.h>\n",
    "\n",
    "__global__ void Dado( float * d_arregloIn, float * d_arregloOut) {\n",
    "\n",
    "    int idx = blockDim.x * blockIdx.x + threadIdx.x ;\n",
    "\n",
    "    d_arregloOut[idx] = ceil( 6*d_arregloIn[idx] ) ;\n",
    "\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "# definimos el número de dados a lanzar\n",
    "\n",
    "N = 50\n",
    "\n",
    "# Iniciamos los arreglos en el GPU\n",
    "\n",
    "# CuRAND es una librería especial para lanzar números aleatorios y hacer cálculos estadísticos\n",
    "\n",
    "a_gpu = curand(N,) # Ver la nota al final del Notebook\n",
    "b_gpu = gpuarray.zeros_like(a_gpu)\n",
    "\n",
    "# Rescatamos la función para luego ejecutarla\n",
    "\n",
    "Dado = mod.get_function(\"Dado\")\n",
    "\n",
    "# El kernel es lanzado de forma muy parecida a CUDA C\n",
    "\n",
    "Dado(a_gpu, b_gpu, block = (N, 1, 1), grid = (1, 1, 1))\n",
    "\n",
    "print b_gpu\n",
    "\n",
    "# Finalmente liberamos la memoria\n",
    "\n",
    "a_gpu.free()\n",
    "b_gpu.free()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este primer código creamos únicamente un lanzador de $N$ dados de $6$ caras. Ahora pasemos a calculos un poco más interesantes.\n",
    "\n",
    "**[1]** Como primer ejercicio tendrás que modificar el código de arriba de tal forma que *en el GPU* se calculen las frecuencias de cada uno de los valores obtenidos. El resultado final tiene que ser un `arreglo` en el cual estén las frecuencias.\n",
    "\n",
    "Puedes basarte en el siguiente código de Python\n",
    "\n",
    "```Python\n",
    "\n",
    "F = np.zeros(6)\n",
    "N = 50\n",
    "\n",
    "for i in resultado\n",
    "    for j in 1:6\n",
    "        if i == j\n",
    "            F[i] += 1./N\n",
    "            \n",
    "```\n",
    "\n",
    "Puedes graficar estos valores en un histograma usando la funcion \n",
    "```Python \n",
    "np.hist()\n",
    "``` \n",
    "para luego repetir el experimento con el mismo valor de $N$ y luego aumentando el valor.\n",
    "\n",
    "¿Qué observas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[2]** En el histograma del ejercicio pasado se logra observar cómo entre mayor es el número de tiros, más se acerca la frecuencia de cada cara a la frecuencia teórica ($\\frac{1}{6}$). Ahora tu trabajo será de calcular la desviación entre la frecuencia obtenida y el valor teórico. Evidentemente este cálculo debe de hacerse en el `GPU`. \n",
    "\n",
    "Ahora buscamos observar como graficar observar la desviación entre la frecuencia obtenida y su valor teórico. Al graficar directamente la desviación obtenemos una gráfica en la que no se observa mucho puesto que hay un decaimiento muy rápido para luego converger hacia 0. Sin embargo, al graficar el logaritmo de la desviación obtenemos este tipo de comportamiento el cual nos revela el caracter exponencial de la desviación con respecto al número de tiros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=Imagenes/Desviacion.png align=center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Ejercicio teórico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Pensemos sólo en el lado $1$. Sea $p := \\frac{1}{6}$ la probabilidad de que caiga en este lado.\n",
    "Si lanzamos 2 veces, ¿cuál es la probabilidad de que salgan (i) cero veces $1$; (ii) una vez $1$; (iii) dos veces $1$?\n",
    "\n",
    "(b) Si lanzamos 3 veces, ¿cuáles son las probabilidades de que salga cada número posible de $1$s entre 0 y 3?\n",
    "\n",
    "(c) Si lanzamos N veces, ¿cuáles son las probabilidades?\n",
    "\n",
    "(d) ¿Cuál es el valor *promedio* que sale? ¿Qué otra cantidad podríamos querer calcular?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribución binomial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora pasemos a otro tipo de distribución de probabilidades basada en el **ensayo de Bernoulli**. La idea principal es sencilla: Un cierto evento tiene una probabilidad $p$ de éxito. Si el evento es exitoso, entonces se marca con el valor $1$. Sino, se obtiene el valor $0$.\n",
    "\n",
    "Tomemos el ejemplo del dado. El evento exitoso será el obtener la cara con valor $1$, lo cual quiere decir que tenemos una probabilidad $p = \\frac{1}{6}$ de que nuestro evento sea exitoso.\n",
    "\n",
    "Al repetir el lanzamiento $N$ veces, entonces podemos obtener la *distribución de probabilidad* $Y_{N}$, la cual nos dará la colección de todas las probabilidades de que el evento sea exitoso cuando se repite $i$ veces el experimento. $i = 1, ..., N$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para todo lo siguiente supondremos que nuestro evento exitoso será obtener un $6$ a la hora de tirar un dado.\n",
    "\n",
    "**[3]** Ahora pasemos a algo un poco más complicado. Escribe un `kernel` que haga $N$ ensayos de Bernoulli y que calcule la proporción de eventos exitosos.\n",
    "\n",
    "Para este problema tendremos distintas manera de obetener el resultado **dentro** del `GPU`(en el `CPU` el problema es trivial). \n",
    "\n",
    "La manera fácil y no eficiente es escribir un `kernel` en el cual sumemos un $1$ si el evento fue exitoso. Esto puede hacerse con un condicional `if`. \n",
    "\n",
    "En el caso en el cual nos decantemos por algo más eficiente, tendremos que recurrir a un `kernel` más sofisticado. El tipo de operación que se hará se llama \"reducción\" y ha sido ampliamente discutido a lo largo de blogs y foros. \n",
    "\n",
    "La idea es esta. Se dividirá el arreglo en el cual se tiene la información del éxito de los eventos en bloques de una cierta dimensión. En cada uno de estos bloques se sumarán las entradas (ceros y unos) y el resultado estará en la primera entrada de cada bloque. \n",
    "\n",
    "En un segundo tiempo, el primer bloque será llenado con los resultados de los demás bloques, obteniendo de nuevo un número de bloques llenos de información. La suma se repetirá de nuevo, y así el procedimiento hasta obtener un solo resultado con la suma de todos los bloques. \n",
    "\n",
    "Como ejemplo, supongamos un arreglo con 18 entradas que separaremos en 5 bloques de 4 entradas. Después del primer paso obtendremos que la primera entrada de cada uno de los 5 bloques será la suma de sus 4 correspondientes entradas. \n",
    "\n",
    "Con estos 5 resultados podemos llenar entonces un bloque de 4 entradas y tener otro con una sola entrada distinta de 0. Hacemos de nuevo el mismo procedimiento, para obtener en el primer bloque la suma de los cuatro resultados. La entrada del segundo bloque quedó intacta.\n",
    "\n",
    "Finalmente, sólo habrá que sumar las últimas dos entradas restantes para obtener el resultado deseado.\n",
    "\n",
    "Si el lector desea implementar y aprender esta herramienta, en las referencias colocamos un documento de NVIDIA en el cual se explica paso a paso un kernel de reducción muy sofisticado. Esta alternativa es altamente recomendable por todos los usos que se le puede dar.\n",
    "\n",
    "**[4]** Finalmente calcula la distribución de probabilidad $Y_N$ con los resultados obtenidos en el inciso anterior.\n",
    "\n",
    "Aquí te recomendamos usar distintos `kernels`, uno `__device__` con el que calcules la proporción de eventos exitosos, y otro `__global__` con el que calcules $Y_N$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La distribución de probabilidad de $Y_{N,p}$ se llama una *distribución binomial*. Se dice que es una distribución de probabilidad *discreta*, ya que los valores que toma son valores discretos. \n",
    "\n",
    "La notación que se utiliza es\n",
    "\n",
    "$$X \\sim B(N,p)$$\n",
    "\n",
    "para decir que $X$ es una variable aleatoria con distribución de probabilidad binomial con parámetros $N$ y $p$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nota sobre cuRAND en PyCUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este primer Notebook, y a partir de ahora usaremos la librería cuRAND la cual nos permite generar números aleatorios para cada `thread` *dentro* del `GPU`. Esto tiene grandes ventajas con respecto a la utilización de la función `rand()` dentro de `numpy`, sobre todo debido al mayor control que nos da cuRAND sobre los generadores. Sin embargo, cuRAND tiene la desventaja que el máximo número de generadores activos en `GPU`'s tipo Tesla es de 256. Para el caso de `GPU`'s tipo Fermi, 1024 generadores pueden ser activados sin -en principio- tener mayor problema.\n",
    "\n",
    "**Recomendamos** ampliamente leer las dos primeras partes del Apéndice 3 para aprender un poco más sobre como se generan números pseudo-aleatorios y cuasi-aleatorios en el GPU con ayuda de cuRAND."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Wiki de [Probabilidad Bayesiana](https://en.wikipedia.org/wiki/Bayesian_probability)\n",
    "+ Wiki de [Probabilidad Frecuentisca](https://en.wikipedia.org/wiki/Frequentist_probability)\n",
    "+ WIki de [Ensayo de Bernoulli](https://es.wikipedia.org/wiki/Ensayo_de_Bernoulli) y de la [Distribución Binomial](https://en.wikipedia.org/wiki/Binomial_distribution)\n",
    "+ Documento de NVIDIA donde se expone un [kernel de reducción](http://developer.download.nvidia.com/compute/cuda/1.1-Beta/x86_website/projects/reduction/doc/reduction.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
