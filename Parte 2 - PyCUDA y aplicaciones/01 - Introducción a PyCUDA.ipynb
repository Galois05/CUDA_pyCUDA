{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Por qué PyCUDA?\n",
    "\n",
    "Hasta ahora hemos visto que si bien CUDA no es un lenguaje imposible de aprender, puede llegar a ser un dolor de cabeza el tener muchos apuntadores y manejar la memoria de un modo tan rudimentario.\n",
    "\n",
    "Sin embargo hay alternativas que nos permiten trabajar en entornos más agradables, un ejemplo de ellos es [PyCUDA](http://mathema.tician.de/software/pycuda/) creado con [Andreas Klöckner](http://mathema.tician.de/). Básicamente PyCUDA se encarga de mapear todo CUDA dentro de Python. \n",
    "\n",
    "Por poner un ejemplo, un código simple sería el siguiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "import pycuda.autoinit\n",
    "import pycuda.driver as drv\n",
    "import numpy\n",
    "\n",
    "from pycuda.compiler import SourceModule\n",
    "mod = SourceModule(\"\"\"\n",
    "__global__ void multiplicar(float *dest, float *a, float *b)\n",
    "{\n",
    "  const int i = threadIdx.x;\n",
    "  dest[i] = a[i] * b[i];\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "multiplicar = mod.get_function(\"multiplicar\")\n",
    "\n",
    "a = numpy.random.randn(400).astype(numpy.float32)\n",
    "b = numpy.random.randn(400).astype(numpy.float32)\n",
    "\n",
    "dest = numpy.zeros_like(a)\n",
    "\n",
    "multiplicar(\n",
    "        drv.Out(dest), drv.In(a), drv.In(b),\n",
    "        block=(400,1,1), grid=(1,1))\n",
    "\n",
    "print dest-a*b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al correr este programa vamos a obtener un montón de ceros; algo no muy interesante. Sin embargo detrás de escenas sí pasó algo interesante.\n",
    "\n",
    "- PyCUDA compiló el código fuente y lo cargó a la tarjeta.\n",
    "- Se asignó memoria automáticamente, además de copiar las cosas de CPU a GPU y de vuelta.\n",
    "- Por último la limpieza (liberación de memoria) se hace sola.\n",
    "\n",
    "**Útil ¿cierto?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usando PyCUDA\n",
    "\n",
    "Para empezar debemos importar e incializar PyCUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "from pycuda.compiler import SourceModule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transferir datos\n",
    "\n",
    "El siguiente paso es transferir datos al GPU. Principalmente arreglos de numpy. Por ejemplo, tomemos un arreglo de números aleatorios de $4 \\times 4$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "a = numpy.random.randn(4,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sin embargo nuestro arreglo `a` consiste en números de doble precisión, dado que no todos los GPU de NVIDIA cuentan con doble precisión es que hacemos lo siguiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = a.astype(numpy.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finalmente, necesitmos un arreglo hacia el cuál transferir la información, así que deberíamos guardar la memoria en el dispositivo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_gpu = cuda.mem_alloc(a.nbytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "como último paso, necesitamos tranferir los datos al GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cuda.memcpy_htod(a_gpu, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejecutando kernels\n",
    "\n",
    "\n",
    "Durante este capítulo nos centraremos en un ejemplo muy simple. Escribir un código para duplicar cada una de las entradas en un arreglo, en seguida escribimos el kernel en CUDA C, y se lo otorgamos al constructor de `pycuda.compiler.SourceModule`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mod = SourceModule(\"\"\"\n",
    "  __global__ void duplicar(float *a)\n",
    "  {\n",
    "    int idx = threadIdx.x + threadIdx.y*4;\n",
    "    a[idx] *= 2;\n",
    "  }\n",
    "  \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si no hay errores, el código ahora ha sido compilado y cargado en el dispositivo. Encontramos una referencia a nuestra `pycuda.driver.Function` y la llamamos, especificando `a_gpu` como el argumento, y un tamaño de bloque de $4\\times 4$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "func = mod.get_function(\"duplicar\")\n",
    "func(a_gpu, block=(4,4,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente recogemos la información del GPU y la mostramos con el `a` original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.88811827  0.94264054 -0.34075302 -2.03711843]\n",
      " [-0.2103018  -1.31252909 -1.84110713 -0.77667522]\n",
      " [ 1.27351296  3.81645846  0.35528642 -0.42018121]\n",
      " [-0.0212212  -0.9973371  -2.42704487  1.55292344]]\n",
      "[[ 1.44405913  0.47132027 -0.17037651 -1.01855922]\n",
      " [-0.1051509  -0.65626454 -0.92055357 -0.38833761]\n",
      " [ 0.63675648  1.90822923  0.17764321 -0.21009061]\n",
      " [-0.0106106  -0.49866855 -1.21352243  0.77646172]]\n"
     ]
    }
   ],
   "source": [
    "a_duplicado = numpy.empty_like(a)\n",
    "cuda.memcpy_dtoh(a_duplicado, a_gpu)\n",
    "print a_duplicado\n",
    "print a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Y eso es todo! Hemos terminado con el trabajo. PyCUDA se encarga de hacer toda la limpieza por nosotros."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
