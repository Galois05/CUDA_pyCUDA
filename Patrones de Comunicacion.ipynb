{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of things to do:\n",
    "\n",
    "- Map\n",
    "    * Vectors\n",
    "- Gather\n",
    "- Scatter\n",
    "- Stencil\n",
    "- Transpose\n",
    "\n",
    "A thread Block programming example to show that it's not predefined the way the threads are launched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#El modelo de programación en paralelo\n",
    "\n",
    "El lector podrá ahora darse cuenta por sí mismo que hay diferencias al programar en paralelo, con respecto a la forma usual. La principal de ellas es que el GPU no es un procesador serial, sino un procesador *stream*. Un procesador serial, también conocido como arquitectura de von Neumann, ejecuta instrucciones serialmente, actualizando la memoria a medida que avanza. Un procesador en *stream* funciona de una manera ligeramente diferente, ejecutando una función (tal como un fragmento de programa) en un conjunto de registros de entrada, produciendo un conjunto de registros de salida (e.g. pixeles sombreados) en paralelo. Los procesadores en stream, típicamente se refieren a dicha función como *kernel* y al conjunto de registros como *stream* (muy imaginativos). La información es lanzada al procesador, operada vía una función *kernel*, y sacada a la memoria, como se muestra en la figura 1. Cada elemento pasado al procesador es procesado independientemente, sin ser influido por los demás elementos. Esto permite a la arquitectura ejecutar un programa en paralelo sin la necesidad de exponer las unidades paralelas o cualquier construcción en paralelo al programador. Es por dicha razón que al escribir la función kernel en el capítulo pasado no notamos el paralelismo, no fue sino hasta el momento de lanzar el kernel que vimos esto.\n",
    "\n",
    "![](http://http.developer.nvidia.com/GPUGems/elementLinks/fig37-01.jpg)\n",
    "\n",
    "<h6 align=\"center\">Figura 1: Modelo de ejecución de un programa en el GPU (imagen tomada de los GPUGems de NVIDIA) </h6>\n",
    "\n",
    "Y qué tal si quisiésemos hacer física con esto, sería increíblemente incómodo que el único tipo de dato que pudiésemos manejar fuera el sombreado de un pixel; sin embargo, gracias a los avances en GPU se pueden manejar registros que no necesariamente son pixeles y sombreados; bien podría ser un conjunto arbitrario de datos, por ejemplo puntos de una red y ecuaciones fisicas. Digamos, que queremos implementar una simulación simple de partículas libres y dejar que el GPU lleve a cabo la mayor parte de las operaciones físicas. Usando texturas de punto flotante y buffers de pixel (pbuffers), guardamos la posición de las partículas, valocidades, y orientaciones. Un kernel hace los cálculos necesarios para obtener la nueva posición de cada partícula. Para calcular todas y cada una de las nuevas posiciones simplemente tomamos un cuadrante que tenga tantos pixeles como partículas, tal y como se muestra en la figura 2. Las coordenadas de textura para el cuadrante indican al kernel cuál de las partículas guardadas procesará. El resultado guardado en el pbuffer contiene los valores de las nuevas posiciones.\n",
    "\n",
    "![](http://http.developer.nvidia.com/GPUGems/elementLinks/fig37-02.jpg)\n",
    "\n",
    "<h6 align=\"center\">Figura 2: Ejemplo de un sistema de partículas (imagen tomada de los GPUGems de NVIDIA) </h6>\n",
    "\n",
    "Este ejemplo de un sistema de partículas demuestra una obvia pero útil aplicación del GPU para el cómputo de propósito general (GPGPU). La operación de actualizar la posición de las partículas puede generalizarse al proceso de aplicar una función a un arreglo. Esta operación - también llamada mapeo en lenguajes de programación funcional - puede ser usada para una amplia variedad de aplicaciones.\n",
    "\n",
    "Pero **¿qué es este mapeo del que tanto hablamos?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Patrones de comunicación\n",
    "\n",
    "##Mapeo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Referencias\n",
    "\n",
    "1. [Curso de Udacity - Intro to Parallel Programming](https://www.udacity.com/course/intro-to-parallel-programming--cs344)\n",
    "2. [GPUGems - Capítulo 37](http://http.developer.nvidia.com/GPUGems/gpugems_ch37.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Materiales adicionales\n",
    "\n",
    "1. [GPUGems](http://developer.nvidia.com/object/gpu_gems_home.html)\n",
    "2. [gpgpu.org](http://gpgpu.org/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
